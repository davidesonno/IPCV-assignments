{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNBgGYg_lpVN"
      },
      "source": [
        "# **Product Recognition of Food Products**\n",
        "\n",
        "## Image Processing and Computer Vision - Assignment Module \\#1\n",
        "\n",
        "\n",
        "Contacts:\n",
        "\n",
        "- Prof. Giuseppe Lisanti -> giuseppe.lisanti@unibo.it\n",
        "- Prof. Samuele Salti -> samuele.salti@unibo.it\n",
        "- Alex Costanzino -> alex.costanzino@unibo.it\n",
        "- Francesco Ballerini -> francesco.ballerini4@unibo.it\n",
        "\n",
        "\n",
        "Computer vision-based object detection techniques can be applied in super market settings to build a system that can identify products on store shelves.\n",
        "An example of how this system could be used would be to assist visually impaired customers or automate common store management tasks like detecting low-stock or misplaced products, given an image of a shelf in a store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW42NlZsyTv0"
      },
      "source": [
        "## Task\n",
        "Develop a computer vision system that, given a reference image for each product, is able to identify such product from one picture of a store shelf.\n",
        "\n",
        "<figure>\n",
        "<a href=\"https://imgbb.com/\">\n",
        "  <center>\n",
        "  <img src=\"https://i.ibb.co/TwkMWnH/Screenshot-2024-04-04-at-14-54-51.png\" alt=\"Screenshot-2024-04-04-at-14-54-51\" border=\"0\" width=\"300\" />\n",
        "</a>\n",
        "</figure>\n",
        "\n",
        "For each type of product displayed in the\n",
        "shelf the system should report:\n",
        "1. Number of instances;\n",
        "1. Dimension of each instance (width and height in pixel of the bounding box that enclose them);\n",
        "1. Position in the image reference system of each instance (center of the bounding box that enclose them).\n",
        "\n",
        "#### Example of expected output\n",
        "```\n",
        "Product 0 - 2 instance found:\n",
        "  Instance 1 {position: (256, 328), width: 57px, height: 80px}\n",
        "  Instance 2 {position: (311, 328), width: 57px, height: 80px}\n",
        "Product 1 â€“ 1 instance found:\n",
        ".\n",
        ".\n",
        ".\n",
        "```\n",
        "\n",
        "### Track A - Single Instance Detection\n",
        "Develop an object detection system to identify single instance of products given one reference image for each item and a scene image.\n",
        "\n",
        "The system should be able to correctly identify all the product in the shelves\n",
        "image.\n",
        "\n",
        "### Track B - Multiple Instances Detection\n",
        "In addition to what achieved at step A, the system should also be able to detect multiple instances of the same product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fIbZJKq16ba"
      },
      "source": [
        "## Data\n",
        "Two folders of images are provided:\n",
        "* **Models**: contains one reference image for each product that the system should be able to identify.\n",
        "* **Scenes**: contains different shelve pictures to test the developed algorithm in different scenarios. The images contained in this folder are corrupted by noise.\n",
        "\n",
        "#### Track A - Single Instance Detection\n",
        "* **Models**: {ref1.png to ref14.png}.\n",
        "* **Scenes**: {scene1.png to scene5.png}.\n",
        "\n",
        "#### Track B - Multiple Instances Detection\n",
        "* **Models**: {ref15.png to ref27.png}.\n",
        "* **Scenes**: {scene6.png to scene12.png}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjP3GCdujYlw"
      },
      "outputs": [],
      "source": [
        "from importlib.util import find_spec\n",
        "\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    !cp -r /content/drive/MyDrive/AssignmentsIPCV/dataset.zip ./\n",
        "    !unzip dataset.zip\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KRBeGbKsEDe"
      },
      "source": [
        "## Evaluation criteria\n",
        "1. **Procedural correctness**. There are several ways to solve the assignment. Design your own sound approach and justify every decision you make;\n",
        "\n",
        "2. **Clarity and conciseness**. Present your work in a readable way: format your code and comment every important step;\n",
        "\n",
        "3. **Correctness of results**. Try to solve as many instances as possible. You should be able to solve all the instances of the assignment, however, a thoroughly justified and sound procedure with a lower number of solved instances will be valued **more** than a poorly designed approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASSIGNMENT:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "models_path=\"dataset/models/\"\n",
        "scenes_path=\"dataset/scenes/\"\n",
        "\n",
        "products_a=[f\"{models_path}ref{i}.png\" for i in range(1,15)]\n",
        "products_b=[f\"{models_path}ref{i}.png\" for i in range(15,28)]\n",
        "\n",
        "scenes_a=[f\"{scenes_path}scene{i}.png\" for i in range(1,6)]\n",
        "scenes_b=[f\"{scenes_path}scene{i}.png\" for i in range(6,13)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 7, figsize=(14, 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, image in enumerate(products_b):\n",
        "    axes[i].imshow(cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB))\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(image[len(models_path):])\n",
        "    if i==len(products_b)-1:\n",
        "        for ax in axes[i+1:]:\n",
        "            ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 7, figsize=(14, 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, image in enumerate(scenes_b):\n",
        "    axes[i].imshow(cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB))\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(image[len(scenes_path):])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRACK A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX=225\n",
        "\n",
        "def window_elements(P, W, i, j):\n",
        "    elements=P[max(0,i-(W-1)//2):min(P.shape[0]-1,i+(W-1)//2)+1,max(0,j-(W-1)//2):min(P.shape[1]-1,j+(W-1)//2)+1]\n",
        "    return elements.reshape((np.prod(elements.shape),))\n",
        "\n",
        "\n",
        "def uncorrupted(a):\n",
        "    return a[(a > 0) & (a < MAX)]\n",
        "\n",
        "\n",
        "def find_median(a):\n",
        "    return np.median(a)\n",
        "\n",
        "\n",
        "def find_mean(a):\n",
        "    return np.mean(a)\n",
        "\n",
        "\n",
        "def only_0_and_MAX(a):\n",
        "    for element in a:\n",
        "        if element!=0 and element !=MAX:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def only_0(a):\n",
        "    for element in a:\n",
        "        if element!=0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def only_MAX(a):\n",
        "    for element in a:\n",
        "        if element!=MAX:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def adaptive_approach(P):\n",
        "    W=3\n",
        "    h=2\n",
        "    Wmax=9\n",
        "    width,height=P.shape\n",
        "    for i in range(width):\n",
        "        for j in range(height):\n",
        "            # print(j)\n",
        "            if P[i,j]>0 and P[i,j]<MAX:\n",
        "                # print('non corrotto', P[i,j])\n",
        "                continue\n",
        "            v=window_elements(P,W,i,j)\n",
        "            V=uncorrupted(v)\n",
        "            N=len(V)\n",
        "            while W<=Wmax:\n",
        "                if N>=W:\n",
        "                    # print('n>=W', P[i,j])\n",
        "                    P[i,j]=find_median(V)\n",
        "                    break\n",
        "                if W<Wmax:\n",
        "                    if N<W: #case I\n",
        "                        W+=h\n",
        "                        v=window_elements(P,W,i,j)\n",
        "                        V=uncorrupted(v)\n",
        "                        N=len(V)\n",
        "                        # print(W,N)\n",
        "                        # print('1')\n",
        "                    else: #case II\n",
        "                        P[i,j]=find_median(V)\n",
        "                        W=3\n",
        "                        # print('2')\n",
        "                        break\n",
        "                if W==Wmax:\n",
        "                    if N<W and N!=0: #caseIII\n",
        "                        P[i,j]=find_mean(V)\n",
        "                        # print('3')\n",
        "                        break\n",
        "                    if only_0_and_MAX(v): #caseIV\n",
        "                        P[i,j]=find_mean(v)\n",
        "                        # print('4')\n",
        "                        break\n",
        "                    if only_0(v): #caseV\n",
        "                        P[i,j]=MAX\n",
        "                        # print('5')\n",
        "                        break\n",
        "                    if only_MAX(v): #caseVI\n",
        "                        P[i,j]=0\n",
        "                        # print('6')\n",
        "                        break\n",
        "    return P\n",
        "\n",
        "\n",
        "def adaptive_davide(P):\n",
        "    h=2\n",
        "    Wmax=9\n",
        "    width,height=P.shape\n",
        "    \n",
        "    for i in range(width):\n",
        "        for j in range(height):\n",
        "            W=3\n",
        "            if P[i][j] > 0 and P[i][j] < MAX:\n",
        "                continue\n",
        "            \n",
        "            while W <= Wmax:\n",
        "                v = window_elements(P, W, i, j)\n",
        "                V = uncorrupted(v)\n",
        "                N = len(V)\n",
        "                # print(f'P:{i,j} N:{N}, W:{W}')\n",
        "                # print(f'V:{np.sort(V)}')\n",
        "                if N>=W:\n",
        "                    P[i][j]=find_median(V)\n",
        "                    # print('n>=W')\n",
        "                    break\n",
        "                else:\n",
        "                    if W < Wmax:\n",
        "                        if N < W: #case I\n",
        "                            W += h\n",
        "                            # print('Case1')\n",
        "                            continue\n",
        "                        else: #case II\n",
        "                            P[i][j] = find_median(V)\n",
        "                            W = 3\n",
        "                            print('Case2')\n",
        "                            break\n",
        "                    \n",
        "                    if W==Wmax:\n",
        "                        if N < W and N != 0: #caseIII\n",
        "                            P[i][j]=find_mean(V)\n",
        "                            print('Case3')\n",
        "                            break\n",
        "                        if only_0_and_MAX(v): #caseIV\n",
        "                            P[i][j]=find_mean(v)\n",
        "                            print('Case4')\n",
        "                            break\n",
        "                        if only_0(v): #caseV\n",
        "                            P[i][j]=MAX\n",
        "                            print('Case5')\n",
        "                            break\n",
        "                        if only_MAX(v): #caseVI\n",
        "                            P[i][j]=0\n",
        "                            print('Case6')\n",
        "                            break\n",
        "            # print(f\"New P_i_j{P[i,j]}\\n\")\n",
        "    return P\n",
        "\n",
        "def denoise_image(image, filters):\n",
        "    '''\n",
        "    filters=[\n",
        "        {name:filter1\n",
        "            n_iter:...,\n",
        "            params:{\n",
        "                ...\n",
        "            }\n",
        "        },\n",
        "        {name:filter2\n",
        "            n_iter:...,\n",
        "            params:{\n",
        "                ...\n",
        "            }\n",
        "        },\n",
        "        ...\n",
        "    ]\n",
        "    '''\n",
        "    for filter in filters:\n",
        "        for _ in range(filter['n_iter']):\n",
        "            match filter['name']:\n",
        "                case \"mean\":\n",
        "                    '''\n",
        "                    {\"ksize\" : 15}\n",
        "                    '''\n",
        "                    k_size = filter['params']['ksize']\n",
        "                    mean_kernel = np.ones([k_size, k_size])/(k_size**2)\n",
        "                    image = cv2.filter2D(image, -1, mean_kernel)\n",
        "\n",
        "                case \"median\":\n",
        "                    '''\n",
        "                    {\"ksize\" : 11}\n",
        "                    '''\n",
        "                    image = cv2.medianBlur(image, **filter['params'])\n",
        "\n",
        "                case \"bilateral\":\n",
        "                    '''\n",
        "                    {\"d\" : 3,\n",
        "                    \"sigmaColor\" : 2,\n",
        "                    \"sigmaSpace\" : 1.5}\n",
        "                    '''\n",
        "                    image = cv2.bilateralFilter(\n",
        "                        image, **filter['params'])\n",
        "\n",
        "                case 'gaussian':\n",
        "                    '''\n",
        "                    {\"sigmaX\" : 2}\n",
        "                    '''\n",
        "                    sigmaX = filter['params']['sigmaX']\n",
        "                    ksize = 2*int(np.ceil(3*sigmaX)) + 1\n",
        "                    image = cv2.GaussianBlur(image, (ksize, ksize), sigmaX)\n",
        "\n",
        "                case 'non_local_means':\n",
        "                    '''\n",
        "                    {'templateWindowSize':5,\"searchWindowSize\":21, \"h\":3, \"hColor\": 20}\n",
        "                    '''\n",
        "                    image = cv2.fastNlMeansDenoisingColored(\n",
        "                        image, **filter['params'])\n",
        "\n",
        "                case 'canny':\n",
        "                    '''\n",
        "                    {'threshold1':5,\"threshold2\":21}\n",
        "                    '''\n",
        "                    image = cv2.Canny(image, **filter['params'])\n",
        "\n",
        "                case \"adaptive\":\n",
        "                    channel1 = image[:, :, 0]\n",
        "                    channel2 = image[:, :, 1]\n",
        "                    channel3 = image[:, :, 2]\n",
        "                    image[:, :, 0] = adaptive_approach(channel1)\n",
        "                    image[:, :, 1] = adaptive_approach(channel2)\n",
        "                    image[:, :, 2] = adaptive_approach(channel3)\n",
        "\n",
        "                case \"adaptive2\":\n",
        "                    image = adaptive_davide(image)\n",
        "                    # channel1 = image[:, :, 0]\n",
        "                    # channel2 = image[:, :, 1]\n",
        "                    # channel3 = image[:, :, 2]\n",
        "                    # image[:, :, 0] = adaptive_davide(channel1)\n",
        "                    # image[:, :, 1] = adaptive_davide(channel2)\n",
        "                    # image[:, :, 2] = adaptive_davide(channel3)\n",
        "\n",
        "                case 'sharpen':\n",
        "                    kernel = np.array([[0, -1, 0],\n",
        "                                       [-1, 5, -1],\n",
        "                                       [0, -1, 0]])\n",
        "                    image = cv2.filter2D(image, -1, kernel=kernel)\n",
        "\n",
        "                case 'emboss':\n",
        "                    kernel = np.array([[-2, -1, 0],\n",
        "                                       [-1, 1, 1],\n",
        "                                       [0, 1, 2]])\n",
        "                    image = cv2.filter2D(image, -1, kernel=kernel)\n",
        "                case _: pass\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(image):\n",
        "    return (image.astype(float)*255.0/225).astype('uint8')\n",
        "\n",
        "def diagonal(points,point2=None):\n",
        "    if point2:\n",
        "        return np.sqrt((points[0]-point2[0])**2+(points[1]-point2[1])**2)\n",
        "    return np.sqrt(np.sum(np.subtract(points[:1,:],points[1:,:])**2))\n",
        "\n",
        "def get_geometry(corners):\n",
        "    return {'position': tuple(np.round((np.sum(corners,axis=0)/4)[0],0).astype(int)),\n",
        "        'width': f'{max(diagonal(corners[1:3,:]),diagonal(np.vstack((corners[0,:], corners[3,:])))):0.0f}px',\n",
        "        'height': f'{max(diagonal(corners[0:2,:]),diagonal(corners[2:4,:])):0.0f}px'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_used(settings):\n",
        "    aux=[filter for filter in settings if ( 'matching_settings' in filter.keys() or filter['n_iter']>0)]\n",
        "    display(aux)\n",
        "\n",
        "\n",
        "def inside(center,image_shape): # center is (x;y), shape is (rows,columns)\n",
        "    # return True\n",
        "    return (center[0]>=0 and center[0]<image_shape[1]) and (center[1]>=0 and center[1]<image_shape[0])\n",
        "\n",
        "\n",
        "def check_boundings(point,rectangle, tollerance=None):\n",
        "    try:\n",
        "        pointX,pointY=point\n",
        "        centerX,centerY=rectangle['position']\n",
        "        sizeX=int(rectangle['width'][:-2])\n",
        "        sizeY=int(rectangle['height'][:-2])\n",
        "        return (centerX-sizeX/2<=pointX and pointX<=centerX+sizeX/2) and (centerY-sizeY/2<=pointY and pointY<=centerY+sizeY/2)\n",
        "    except ValueError:\n",
        "        print(point,rectangle)\n",
        "        return False\n",
        "\n",
        "def flag_same_products_SI(results,method='overlapping_center',method_param=50,show_concentric_texts=False):\n",
        "    '''\n",
        "    per ogni scena \n",
        "        per ogni coppia di prodotti\n",
        "            se hanno lo \"stesso\" centro flaggo a False quello con meno matches\n",
        "    '''\n",
        "    for scene in results.keys():\n",
        "        keys=list(results[scene].keys())\n",
        "        for product1 in keys:\n",
        "            # results[scene][product1][\"flag\"]=True\n",
        "            for product2 in [k for k in keys if k!=product1]:\n",
        "                match method:\n",
        "                    case 'center_vicinity':\n",
        "                        if diagonal(results[scene][product1][\"geometry\"][\"position\"],results[scene][product2][\"geometry\"][\"position\"])<method_param:\n",
        "                            if show_concentric_texts:\n",
        "                                print(f'scene {scene}: products {product1} and {product2} are found to be concentric')\n",
        "                            if results[scene][product1][\"match_count\"]>results[scene][product2][\"match_count\"]:\n",
        "                                results[scene][product2][\"flag\"]=False\n",
        "                            else:\n",
        "                                results[scene][product1][\"flag\"]=False\n",
        "                    case 'overlapping_center':\n",
        "                        point=results[scene][product1][\"geometry\"][\"position\"] # tuple (x,y)\n",
        "                        if check_boundings(point,results[scene][product2][\"geometry\"]):\n",
        "                            if show_concentric_texts:\n",
        "                                print(f'scene {scene}: products {product1} and {product2} are found to be concentric')\n",
        "                            if results[scene][product1][\"match_count\"]>results[scene][product2][\"match_count\"]:\n",
        "                                results[scene][product2][\"flag\"]=False\n",
        "                            else:\n",
        "                                results[scene][product1][\"flag\"]=False\n",
        "                            \n",
        "                    case _:\n",
        "                        pass\n",
        "\n",
        "\n",
        "def print_single_instances(results: dict,min_match,check_pos):\n",
        "    max_product_len = max(len(str(product)) for scene in results for product in results[scene].keys())\n",
        "    max_match_len = max(len(str(results[scene][product][\"match_count\"])) for scene in results for product in results[scene])\n",
        "    max_x_len = max(len(str(results[scene][product][\"geometry\"][\"position\"][0])) for scene in results for product in results[scene] if inside(results[scene][product]['geometry']['position'], scene_info_a[scene-1][2]))\n",
        "    max_y_len = max(len(str(results[scene][product][\"geometry\"][\"position\"][1])) for scene in results for product in results[scene] if inside(results[scene][product]['geometry']['position'], scene_info_a[scene-1][2]))\n",
        "    max_width_len = max(len(str(results[scene][product][\"geometry\"][\"width\"])) for scene in results for product in results[scene])\n",
        "    max_height_len = max(len(str(results[scene][product][\"geometry\"][\"height\"])) for scene in results for product in results[scene])\n",
        "\n",
        "    for scene in results.keys():\n",
        "        print(f'Scene {scene}:')\n",
        "        for product in results[scene].keys():\n",
        "            # print(results[scene][product]['geometry']['position'])\n",
        "            if (results[scene][product]['match_count'] >= min_match and \n",
        "                 #set to false in `flag_concentric_refs` if refs refers to the same product (they both think to be the same product) \n",
        "                results[scene][product]['flag'] and\n",
        "                (\n",
        "                    (not check_pos) or \n",
        "                    inside(results[scene][product]['geometry']['position'], scene_info_a[scene-1][2])\n",
        "                )  \n",
        "                ):\n",
        "                print(\n",
        "                    f\"\\t\\tInstance {i},\"\n",
        "                    + f\" matches: {product['match_count']:<{max_match_len+1}},\"\n",
        "                    + f\" position: ({product['geometry']['position'][0]:<{max_x_len}},\"\n",
        "                    + f\" {product['geometry']['position'][1]:<{max_y_len-1}}),\"\n",
        "                    + f\" width: {product['geometry']['width']:<{max_width_len-1}},\"\n",
        "                    + f\" height: {product['geometry']['height']:<{max_height_len-1}}\"\n",
        "                )\n",
        "\n",
        "                # print(f\"\\tProduct {f'{product},':<{max_product_len+1}}\"\n",
        "                #     + f\" matches: {f'{results[scene][product]['match_count']},':<{max_match_len+1}}\"\n",
        "                #     + f\" {{position: ({str(results[scene][product]['geometry']['position'][0]):<{max_x_len}},\"\n",
        "                #     + f\" {f'{str(results[scene][product]['geometry']['position'][1])}':<{max_y_len-1}}),\"\n",
        "                #     + f\" width: {f'{results[scene][product]['geometry']['width']}':<{max_width_len-1}},\"\n",
        "                #     + f\" height: {results[scene][product]['geometry']['height']:<{max_height_len-1}}}}\"\n",
        "                #     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "solutions:\n",
        "scene1:1,2  \n",
        "scene2:3,4,5  \n",
        "scene3:6,7,8  \n",
        "scene4:1,(7),8,9,10  \n",
        "scene5:(2),11,12  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRACK B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SHOW_FILTERED = True\n",
        "# Working settings:\n",
        "# [{'name': 'median', 'n_iter': 2, 'params': {'ksize': 3}},\n",
        "#  {'name': 'median', 'n_iter': 2, 'params': {'ksize': 5}},\n",
        "#  {'name': 'median', 'n_iter': 1, 'params': {'ksize': 7}},\n",
        "#  {'matching_settings': {'min_match': 40,\n",
        "#    'check_position': 'overlapping_center'}}]\n",
        "settings_b = [\n",
        "    {'name': 'adaptive',\n",
        "        'n_iter': 0,\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 2,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 2,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 7}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': 'emboss',\n",
        "        'n_iter': 0,\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 9}\n",
        "     },\n",
        "    {'name': \"gaussian\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"sigmaX\": 1.5}\n",
        "     },\n",
        "    {'name': \"mean\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 15}\n",
        "     },\n",
        "    {'name': \"bilateral\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"d\": 9,\n",
        "                   \"sigmaColor\": 150,\n",
        "                   \"sigmaSpace\": 150}\n",
        "     },\n",
        "    {'name': \"non_local_means\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\n",
        "            'templateWindowSize': 9,\n",
        "            \"searchWindowSize\": 21,\n",
        "            \"h\": 3,\n",
        "            \"hColor\": 20}\n",
        "     },\n",
        "    {'name': \"canny\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\n",
        "            'threshold1': 100,\n",
        "            \"threshold2\": 200}\n",
        "     },\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flag_same_products_MI(results,method='overlapping_center',method_param=50,show_concentric_texts=False):\n",
        "    '''\n",
        "    per ogni scena \n",
        "        per ogni coppia di istanza\n",
        "            se hanno lo \"stesso\" centro flaggo a False quella con meno matches\n",
        "    '''\n",
        "    for scene in results.keys():\n",
        "        keys=list(results[scene].keys())\n",
        "        for product1 in keys:\n",
        "            for product2 in [k for k in keys if k != product1]:\n",
        "                for instance1 in range(len(results[scene][product1])):\n",
        "                    for instance2 in range(len(results[scene][product2])):\n",
        "                        match method:\n",
        "                            case 'center_vicinity':\n",
        "                                if diagonal(results[scene][product1][instance1][\"geometry\"][\"position\"],results[scene][product2][instance2][\"geometry\"][\"position\"])<method_param:\n",
        "                                    if show_concentric_texts:\n",
        "                                        print(f'scene {scene}: products {product1} and {product2} are found to be concentric')\n",
        "                                    if results[scene][product1][instance1][\"match_count\"]>results[scene][product2][instance2][\"match_count\"]:\n",
        "                                        results[scene][product2][instance2][\"flag\"]=False\n",
        "                                    else:\n",
        "                                        results[scene][product1][instance1][\"flag\"]=False\n",
        "                            case 'overlapping_center':\n",
        "                                point=results[scene][product1][instance1][\"geometry\"][\"position\"] # tuple (x,y)\n",
        "                                if check_boundings(point,results[scene][product2][instance2][\"geometry\"]):\n",
        "                                    if show_concentric_texts:\n",
        "                                        print(f'scene {scene}: products {product1} and {product2} are found to be concentric')\n",
        "                                    if results[scene][product1][instance1][\"match_count\"]>results[scene][product2][instance2][\"match_count\"]:\n",
        "                                        results[scene][product2][instance2][\"flag\"]=False\n",
        "                                    else:\n",
        "                                        results[scene][product1][instance1][\"flag\"]=False\n",
        "                                    \n",
        "                            case _:\n",
        "                                pass\n",
        "\n",
        "\n",
        "'''\n",
        "    results_b={\n",
        "        scene_index:{\n",
        "            product_1_index:[\n",
        "                {\n",
        "                    'match_count':n,\n",
        "                    'geometry':geom_dict (see get_geometry()),\n",
        "                    'flag':Bool\n",
        "                },\n",
        "                {\n",
        "                    'match_count':n,\n",
        "                    'geometry':geom_dict (see get_geometry()),\n",
        "                    'flag':Bool\n",
        "                },\n",
        "                ...\n",
        "            ],\n",
        "            ...\n",
        "        },\n",
        "        ...\n",
        "    }\n",
        "'''\n",
        "def print_multiple_instances(results: dict,min_match,check_pos):\n",
        "    max_product_len = max(len(str(product)) for scene in results for product in results[scene].keys())\n",
        "    max_match_len = max(len(str(product[\"match_count\"])) for scene in results for products in results[scene] for product in results[scene][products])\n",
        "    max_x_len = max(len(str(product[\"geometry\"][\"position\"][0])) for scene in results for products in results[scene] for product in results[scene][products] if inside(product['geometry']['position'], scene_info_b[scene-1][2]))\n",
        "    max_y_len = max(len(str(product[\"geometry\"][\"position\"][1])) for scene in results for products in results[scene] for product in results[scene][products] if inside(product['geometry']['position'], scene_info_b[scene-1][2]))\n",
        "    max_width_len = max(len(str(product[\"geometry\"][\"width\"])) for scene in results for products in results[scene] for product in results[scene][products])\n",
        "    max_height_len = max(len(str(product[\"geometry\"][\"height\"])) for scene in results for products in results[scene] for product in results[scene][products])\n",
        "\n",
        "    for scene in results.keys():\n",
        "        print(f'Scene {scene}:')\n",
        "        for products in results[scene].keys():\n",
        "            printable_prods=[]\n",
        "            for product in results[scene][products]:\n",
        "                if (product['match_count'] >= min_match and \n",
        "                    product['flag'] and \n",
        "                    (\n",
        "                        (not check_pos) or \n",
        "                        inside(product['geometry']['position'], scene_info_b[scene-1][2])\n",
        "                    )):\n",
        "                    printable_prods.append(product)\n",
        "            num_inside=len(printable_prods)\n",
        "            if num_inside>0:\n",
        "                print(f\"\\tProduct {products:<{max_product_len}} - {num_inside} instance found:\")\n",
        "                for i,product in enumerate(printable_prods,1):\n",
        "                    print(f\"\\t\\tInstance {i},\"\n",
        "                        + f\" matches: {f'{product['match_count']},':<{max_match_len+1}}\"\n",
        "                        + f\" {{position: ({str(product['geometry']['position'][0]):<{max_x_len}}\"\n",
        "                        + f\", {f'{str(product['geometry']['position'][1])}':<{max_y_len-1}}),\"\n",
        "                        + f\" width: {f'{product['geometry']['width']}':<{max_width_len-1}},\"\n",
        "                        + f\" height: {product['geometry']['height']:<{max_height_len-1}}}}\"\n",
        "                        )\n",
        "dicti={1: {\n",
        "        1: [\n",
        "            {'match_count': 509, 'geometry': {'position': (412, 539), 'width': '1049px', 'height': '803px'}, 'flag': True},\n",
        "            {'match_count': 45, 'geometry': {'position': (412, 539), 'width': '1049px', 'height': '803px'}, 'flag': True}\n",
        "            ],\n",
        "        2: [{'match_count': 426, 'geometry': {'position': (1248, 533), 'width': '1047px', 'height': '803px'}, 'flag': True}],\n",
        "        3: [{'match_count': 26, 'geometry': {'position': (1169, 1000), 'width': '300px', 'height': '1690px'}, 'flag': False}],\n",
        "        4: [{'match_count': 30, 'geometry': {'position': (920, 642), 'width': '3px', 'height': '2px'}, 'flag': False}],\n",
        "        5: [{'match_count': 81, 'geometry': {'position': (1246, 562), 'width': '1004px', 'height': '712px'}, 'flag': False}],\n",
        "        6: [{'match_count': 13, 'geometry': {'position': (1457, 111), 'width': '314px', 'height': '1770px'}, 'flag': True}],\n",
        "        7: [{'match_count': 13, 'geometry': {'position': (553486, 37480), 'width': '26242px', 'height': '1159px'}, 'flag': True}],\n",
        "        8: [{'match_count': 21, 'geometry': {'position': (92, 801), 'width': '21px', 'height': '1px'}, 'flag': True}],\n",
        "        9: [],\n",
        "        10:[ {'match_count': 15, 'geometry': {'position': (510, 44), 'width': '310px', 'height': '25px'}, 'flag': True}],\n",
        "        11:[],\n",
        "        12:[ {'match_count': 7, 'geometry': {'position': (2499, -3400), 'width': '17176px', 'height': '19063px'}, 'flag': False}],\n",
        "        13:[ {'match_count': 31, 'geometry': {'position': (1072, 508), 'width': '0px', 'height': '0px'}, 'flag': False}],\n",
        "        14:[ {'match_count': 73, 'geometry': {'position': (1245, 616), 'width': '1037px', 'height': '888px'}, 'flag': False}]\n",
        "    }}\n",
        "# print_multiple_instances(results=dicti,min_match=1,check_pos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_used(points: list, angles, coordinates):\n",
        "    # print(angles)\n",
        "    if angles.size == 0:\n",
        "        return points\n",
        "\n",
        "    aux = points.copy()\n",
        "    geom = get_geometry(angles)\n",
        "    # print(geom)\n",
        "    for point in aux:\n",
        "        if check_boundings(coordinates[point.trainIdx].pt, geom):\n",
        "            # print(coordinates[point.trainIdx].pt)\n",
        "            aux.remove(point)\n",
        "    return aux\n",
        "\n",
        "\n",
        "def remove_used2(points: list, mask, coordinates):\n",
        "    aux = points.copy()\n",
        "    count=0\n",
        "    for i in range(len(mask)):\n",
        "        if mask[i]==1:\n",
        "            aux.pop(i-count)\n",
        "            count+=1\n",
        "    return aux\n",
        "\n",
        "\n",
        "def print_masked(mask, points, coordinates):\n",
        "    for i in range(len(mask)):\n",
        "        if mask[i]==1:\n",
        "            print(coordinates[points[i].trainIdx].pt,points[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_used3(keypoints, descriptors: np.array, angles):\n",
        "    # print(angles)\n",
        "    if angles.size == 0:\n",
        "        return keypoints, descriptors\n",
        "    keypoints = list(keypoints)\n",
        "    geom = get_geometry(angles)\n",
        "    count = 0\n",
        "    for i in range(len(keypoints)):\n",
        "        if check_boundings(keypoints[i-count].pt, geom):\n",
        "            keypoints.pop(i-count)\n",
        "            descriptors = np.delete(descriptors, i-count, 0)\n",
        "            count += 1\n",
        "    return tuple(keypoints), descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters=[\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 7}\n",
        "     }]\n",
        "img_scene=cv2.imread(scenes_b[-1])\n",
        "# img_scene=normalize(img_scene)\n",
        "img_scene=denoise_image(img_scene,filters)[:,0:,:]\n",
        "img_prod=cv2.imread(products_b[3])\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "kp_scene = sift.detect(img_scene)\n",
        "kp_prod = sift.detect(img_prod)\n",
        "# img_visualization = cv2.drawKeypoints(img_scene,kp_scene, None, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(img_scene)\n",
        "plt.show()\n",
        "img_visualization = cv2.drawKeypoints(img_prod,kp_prod, None, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "# plt.imshow(img_visualization)\n",
        "# plt.show()\n",
        "\n",
        "kp_scene, des_scene = sift.compute(img_scene, kp_scene)\n",
        "kp_prod, des_prod = sift.compute(img_prod, kp_prod)\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "search_params = dict(checks = 150)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "matches = flann.knnMatch(des_prod,des_scene,k=2)\n",
        "\n",
        "good = []\n",
        "for m,n in matches:\n",
        "    if m.distance < 0.8*n.distance:\n",
        "        good.append(m)\n",
        "\n",
        "MIN_NUM_MATCHES = 5\n",
        "box=np.array([])\n",
        "while len(good)>MIN_NUM_MATCHES:\n",
        "    # print(len(good))\n",
        "    # good=remove_used(good,box,kp_scene)\n",
        "    try:\n",
        "        kp_scene,des_scene=remove_used3(kp_scene,des_scene,box)\n",
        "        print(des_scene.shape[0])\n",
        "        if des_scene.shape[0]<1:\n",
        "            break\n",
        "        matches = flann.knnMatch(des_prod,des_scene,k=2)\n",
        "        good = []\n",
        "        for m,n in matches:\n",
        "            if m.distance < 0.8*n.distance:\n",
        "                good.append(m)\n",
        "        # print([(m.trainIdx,m.queryIdx) for m in good])\n",
        "\n",
        "        # print(des_scene.shape,len(kp_scene))\n",
        "        src_pts = np.float32([ kp_prod[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "        dst_pts = np.float32([ kp_scene[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
        "\n",
        "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "        matchesMask = mask.ravel().tolist()\n",
        "        # print(np.sum(matchesMask))\n",
        "        if np.sum(matchesMask)<MIN_NUM_MATCHES:\n",
        "            break\n",
        "        # print(matchesMask)\n",
        "        # print_masked(matchesMask,good,kp_scene)\n",
        "\n",
        "        h,w,z = img_prod.shape\n",
        "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "        dst = cv2.perspectiveTransform(pts,M)\n",
        "        box=dst\n",
        "        # print(get_geometry(dst))\n",
        "        img_scene_p = cv2.polylines(img_scene,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
        "        draw_params = dict(matchColor = (255,0,0), # draw matches in red color\n",
        "                        singlePointColor = None, # not draw keypoints only matching lines\n",
        "                        matchesMask = matchesMask, # draw only inliers\n",
        "                        flags = 2) # not draw keypoints only lines\n",
        "        img3 = cv2.drawMatches(img_visualization,kp_prod,img_scene,kp_scene,good,None,**draw_params)\n",
        "        plt.figure(figsize=(15,15))\n",
        "        extent=[ -img_prod.shape[1], img_scene.shape[1],img_prod.shape[0],0]\n",
        "        # print(extent)\n",
        "        # plt.grid()\n",
        "        # plt.xticks(np.arange(-410, 1696,75))\n",
        "        plt.imshow(img3, extent=extent)\n",
        "        plt.show()\n",
        "        # good=remove_used2(good,matchesMask,kp_scene)\n",
        "    except cv2.error:\n",
        "        # print(des_scene.shape)\n",
        "        print('cv2 error',cv2.error.msg)\n",
        "    except IndexError:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "img_scene=cv2.imread(scenes_b[-1], cv2.IMREAD_GRAYSCALE)\n",
        "plt.imshow(img_scene, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters=[\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 7}\n",
        "     },\n",
        "    {'name': \"adaptive2\",\n",
        "        \"n_iter\": 0\n",
        "     }]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "img_scene=cv2.imread(scenes_b[-1])\n",
        "img_scene=denoise_image(img_scene,filters)\n",
        "plt.subplot(221)\n",
        "plt.imshow(img_scene[:,:,0], cmap='gray')\n",
        "plt.subplot(222)\n",
        "plt.imshow(img_scene[:,:,1], cmap='gray')\n",
        "plt.subplot(223)\n",
        "plt.imshow(img_scene[:,:,2], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters=[\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 7}\n",
        "     }]\n",
        "plt.figure(figsize=(20,20))\n",
        "img_scene = cv2.imread(scenes_b[-1])\n",
        "img_scene=denoise_image(img_scene,filters)  \n",
        "kp_scene = sift.detect(img_scene)\n",
        "kp_scene, des_scene = sift.compute(img_scene, kp_scene)\n",
        "img_kp = cv2.drawKeypoints(img_scene, kp_scene, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "plt.imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_used4(keypoints,descriptors,angles):\n",
        "    if angles.size == 0:\n",
        "        return keypoints, descriptors\n",
        "    removed=0\n",
        "    keypoints = list(keypoints)\n",
        "    angles=[tuple(row[0]) for row in angles]\n",
        "    for ikp in range(len(keypoints)):\n",
        "        px, py = keypoints[ikp-removed].pt\n",
        "        count = 0\n",
        "        n = 4\n",
        "        remove=False\n",
        "        for i in range(n):\n",
        "            x1, y1 = angles[i]\n",
        "            x2, y2 = angles[(i + 1) % n]\n",
        "\n",
        "            # Check if the point is exactly on a vertex\n",
        "            if (px, py) == (x1, y1) or (px, py) == (x2, y2):\n",
        "                remove= True\n",
        "\n",
        "            # Check if the point is on the edge\n",
        "            if y1 != y2 and min(y1, y2) <= py <= max(y1, y2):\n",
        "                x_intercept = (py - y1) * (x2 - x1) / (y2 - y1) + x1\n",
        "                if px == x_intercept:\n",
        "                    remove= True\n",
        "\n",
        "            # Check intersections with a ray from the point\n",
        "            if (y1 <= py < y2) or (y2 <= py < y1):\n",
        "                x_intercept = (py - y1) * (x2 - x1) / (y2 - y1) + x1\n",
        "                if px < x_intercept:\n",
        "                    count += 1\n",
        "\n",
        "        if count % 2 == 1 or remove:\n",
        "            # print(f'point:{keypoints[i-removed].pt}, angles:{angles}')\n",
        "            keypoints.pop(ikp-removed)\n",
        "            descriptors = np.delete(descriptors, ikp-removed, 0)\n",
        "            removed += 1\n",
        "    return tuple(keypoints), descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters=[\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 2,\n",
        "        \"params\": {\"ksize\": 3}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 0,\n",
        "        \"params\": {\"ksize\": 5}\n",
        "     },\n",
        "    {'name': \"median\",\n",
        "        \"n_iter\": 1,\n",
        "        \"params\": {\"ksize\": 7}\n",
        "     }]\n",
        "\n",
        "prod=[products_b[i] for i in [3,-1,-2]]\n",
        "\n",
        "#plt.figure(figsize=(20,20))\n",
        "img_scene=cv2.imread(scenes_b[-1])\n",
        "img_scene=denoise_image(img_scene,filters)\n",
        "#plt.imshow(cv2.cvtColor(img_scene,cv2.COLOR_BGR2RGB))\n",
        "#plt.show()\n",
        "for product in prod:\n",
        "    print(f'product {product}')\n",
        "    img_prod = cv2.imread(product)\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    \n",
        "    for channel in range(3):\n",
        "        print(f'channel {channel +1}')\n",
        "        img_scene = cv2.imread(scenes_b[-1])\n",
        "        img_scene=denoise_image(img_scene,filters)\n",
        "        \n",
        "        kp_scene = sift.detect(img_scene[:,:,channel])\n",
        "        kp_prod = sift.detect(img_prod[:,:,channel])\n",
        "        kp_scene, des_scene = sift.compute(img_scene[:,:,channel], kp_scene)\n",
        "        kp_prod, des_prod = sift.compute(img_prod[:,:,channel], kp_prod)\n",
        "        \n",
        "        FLANN_INDEX_KDTREE = 1\n",
        "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "        search_params = dict(checks = 150)\n",
        "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "        matches = flann.knnMatch(des_prod,des_scene,k=2)\n",
        "\n",
        "        good = []\n",
        "        for m,n in matches:\n",
        "            if m.distance < 0.8*n.distance:\n",
        "                good.append(m)\n",
        "\n",
        "        MIN_NUM_MATCHES = 5\n",
        "        box=np.array([])\n",
        "        while len(good)>MIN_NUM_MATCHES:\n",
        "            try:\n",
        "                kp_scene,des_scene=remove_used3(kp_scene,des_scene,box)\n",
        "                # plt.figure(figsize=(20,20))\n",
        "                img_kp = cv2.drawKeypoints(img_scene[:,:, channel], kp_scene, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "                plt.imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "                if des_scene.shape[0]<1:\n",
        "                    break\n",
        "                matches = flann.knnMatch(des_prod,des_scene,k=2)\n",
        "                good = []\n",
        "                for m,n in matches:\n",
        "                    if m.distance < 0.8*n.distance:\n",
        "                        good.append(m)\n",
        "\n",
        "                src_pts = np.float32([ kp_prod[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "                dst_pts = np.float32([ kp_scene[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
        "\n",
        "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "                matchesMask = mask.ravel().tolist()\n",
        "                print(np.sum(matchesMask),des_scene.shape[0])\n",
        "                if np.sum(matchesMask)<MIN_NUM_MATCHES:\n",
        "                    break\n",
        "\n",
        "                h,w = img_prod[:,:,channel].shape\n",
        "                pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "                dst = cv2.perspectiveTransform(pts,M)\n",
        "                box=dst\n",
        "                \n",
        "                img_scene_p = cv2.polylines(img_scene,[np.int32(dst)],True,0,3, cv2.LINE_AA)\n",
        "                draw_params = dict(matchColor = (0,0,0), # draw matches in red color\n",
        "                                singlePointColor = None, # not draw keypoints only matching lines\n",
        "                                matchesMask = matchesMask, # draw only inliers\n",
        "                                flags = 2) # not draw keypoints only lines\n",
        "                #img3 = cv2.drawMatches(img_prod[:,:,channel],kp_prod,img_scene[:,:,channel],kp_scene,good,None,**draw_params)\n",
        "                # extent=[ -img_prod.shape[1], img_scene.shape[1],img_prod.shape[0],0]\n",
        "                # #plt.imshow(img3, 'gray',extent=extent)\n",
        "                # plt.show()\n",
        "                \n",
        "            except cv2.error:\n",
        "                print('cv2 error',cv2.error.msg)\n",
        "            except IndexError:\n",
        "                pass\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
