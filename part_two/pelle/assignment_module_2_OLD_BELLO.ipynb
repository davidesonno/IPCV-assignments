{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNBgGYg_lpVN"
      },
      "source": [
        "# Assignment Module 2: Product Classification\n",
        "\n",
        "The goal of this assignment is to implement a neural network that classifies smartphone pictures of products found in grocery stores. The assignment will be divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVTQUJ4uYH1w"
      },
      "source": [
        "## Preliminaries: the dataset\n",
        "\n",
        "The dataset you will be using contains natural images of products taken with a smartphone camera in different grocery stores:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Granny-Smith.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Pink-Lady.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Lemon.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Banana.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Vine-Tomato.jpg\" width=\"150\">\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Yellow-Onion.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Green-Bell-Pepper.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Arla-Standard-Milk.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Oatly-Natural-Oatghurt.jpg\" width=\"150\">\n",
        "  <img src=\"https://github.com/marcusklasson/GroceryStoreDataset/raw/master/sample_images/natural/Alpro-Fresh-Soy-Milk.jpg\" width=\"150\">\n",
        "</p>\n",
        "\n",
        "The products belong to the following 43 classes:\n",
        "```\n",
        "0.  Apple\n",
        "1.  Avocado\n",
        "2.  Banana\n",
        "3.  Kiwi\n",
        "4.  Lemon\n",
        "5.  Lime\n",
        "6.  Mango\n",
        "7.  Melon\n",
        "8.  Nectarine\n",
        "9.  Orange\n",
        "10. Papaya\n",
        "11. Passion-Fruit\n",
        "12. Peach\n",
        "13. Pear\n",
        "14. Pineapple\n",
        "15. Plum\n",
        "16. Pomegranate\n",
        "17. Red-Grapefruit\n",
        "18. Satsumas\n",
        "19. Juice\n",
        "20. Milk\n",
        "21. Oatghurt\n",
        "22. Oat-Milk\n",
        "23. Sour-Cream\n",
        "24. Sour-Milk\n",
        "25. Soyghurt\n",
        "26. Soy-Milk\n",
        "27. Yoghurt\n",
        "28. Asparagus\n",
        "29. Aubergine\n",
        "30. Cabbage\n",
        "31. Carrots\n",
        "32. Cucumber\n",
        "33. Garlic\n",
        "34. Ginger\n",
        "35. Leek\n",
        "36. Mushroom\n",
        "37. Onion\n",
        "38. Pepper\n",
        "39. Potato\n",
        "40. Red-Beet\n",
        "41. Tomato\n",
        "42. Zucchini\n",
        "```\n",
        "\n",
        "The dataset is split into training (`train`), validation (`val`), and test (`test`) set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pdrmJRnJPd8"
      },
      "source": [
        "The following code cells download the dataset and define a `torch.utils.data.Dataset` class to access it. This `Dataset` class will be the starting point of your assignment: use it in your own code and build everything else around it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POMX_3x-_bZI",
        "outputId": "85d6d0da-cf90-4fce-a2f5-b111dfb54f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GroceryStoreDataset'...\n",
            "remote: Enumerating objects: 6559, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 6559 (delta 45), reused 35 (delta 35), pack-reused 6293\u001b[K\n",
            "Receiving objects: 100% (6559/6559), 116.26 MiB | 10.41 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n",
            "Updating files: 100% (5717/5717), done.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !git clone https://github.com/marcusklasson/GroceryStoreDataset.git\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hiF8xGEYlsu8"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jROSO2qVDxdD"
      },
      "outputs": [],
      "source": [
        "class GroceryStoreDataset(Dataset):\n",
        "\n",
        "    def __init__(self, split: str, transform=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = Path(\"GroceryStoreDataset/dataset\")\n",
        "        self.split = split\n",
        "        self.paths, self.labels = self.read_file()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
        "        img = Image.open(self.root / self.paths[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def read_file(self) -> Tuple[List[str], List[int]]:\n",
        "        paths = []\n",
        "        labels = []\n",
        "\n",
        "        with open(self.root / f\"{self.split}.txt\") as f:\n",
        "            for line in f:\n",
        "                # path, fine-grained class, coarse-grained class\n",
        "                path, _, label = line.replace(\"\\n\", \"\").split(\", \")\n",
        "                paths.append(path), labels.append(int(label))\n",
        "\n",
        "        return paths, labels\n",
        "\n",
        "    def get_num_classes(self) -> int:\n",
        "        return max(self.labels) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBch3dpwNSsW"
      },
      "source": [
        "## Part 1: design your own network\n",
        "\n",
        "Your goal is to implement a convolutional neural network for image classification and train it on `GroceryStoreDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split of **around 60%**. You are free to achieve that however you want, except for a few rules you must follow:\n",
        "\n",
        "- You **cannot** simply instantiate an off-the-self PyTorch network. Instead, you must construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you **cannot** use e.g. `torchvision.models.alexnet`.\n",
        "\n",
        "- Justify every *design choice* you make. Design choices include network architecture, training hyperparameters, and, possibly, dataset preprocessing steps. You can either (i) start from the simplest convolutional network you can think of and add complexity one step at a time, while showing how each step gets you closer to the target ~60%, or (ii) start from a model that is already able to achieve the desired accuracy and show how, by removing some of its components, its performance drops (i.e. an *ablation study*). You can *show* your results/improvements however you want: training plots, console-printed values or tables, or whatever else your heart desires: the clearer, the better.\n",
        "\n",
        "Don't be too concerned with your network performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded **more** points than a poorly experimentally validated model with higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq4GMcxSH8qG"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "def is_installed(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-c\", f\"import {package}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        return True\n",
        "    except subprocess.CalledProcessError:\n",
        "        return False\n",
        "\n",
        "# Upgrade pip\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
        "\n",
        "# Check and install packages if not already installed\n",
        "packages = [\n",
        "    (\"wandb\", \"wandb\"),\n",
        "    (\"torchmetrics\", \"torchmetrics\"),\n",
        "    (\"torchsummary\", \"torchsummary\")\n",
        "]\n",
        "\n",
        "for pkg_name, import_name in packages:\n",
        "    if not is_installed(import_name):\n",
        "        install(pkg_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5VsEPrKH8qH",
        "outputId": "f6213b36-0faf-4ae7-9dca-518d3dfbc396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: python3.11: command not found\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.6/303.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "# THE CODE ABOVE IS QUICKIER than the bash\n",
        "# ! python3.11 -m pip install --upgrade pip\n",
        "# ! pip install -q wandb\n",
        "# ! pip install -q torchmetrics\n",
        "# ! pip install torchsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6dJm-3pH8qJ"
      },
      "source": [
        "### Weights and Biases for following the net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2zmkulI0H8qJ"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "WANDB_USER = \"lollopelle-2-universit-di-bologna\"\n",
        "WANDB_PROJECT = \"IPCV-assignment-2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEaLcecbH8qK"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmeBcj2MH8qK"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import csv\n",
        "import copy\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Third-party library imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils\n",
        "from torchmetrics.classification.accuracy import Accuracy\n",
        "from torchsummary import summary\n",
        "\n",
        "# Torchvision imports\n",
        "from torchvision import transforms as T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32kWjbqzH8qM"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sjbmdhzOH8qN"
      },
      "outputs": [],
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def extract_classes(csv_file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract unique pairs of IDs and labels from a CSV file.\n",
        "\n",
        "    This function reads a CSV file, extracts the third and fourth columns,\n",
        "    and creates a dictionary with unique pairs of IDs (from the fourth column)\n",
        "    and labels (from the third column).\n",
        "\n",
        "    Parameters:\n",
        "    csv_file_path (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with IDs as keys and labels as values.\n",
        "    \"\"\"\n",
        "\n",
        "    # Dictionary to store the unique pairs\n",
        "    classes = {}\n",
        "\n",
        "    # Read the CSV file\n",
        "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "\n",
        "        # Skip the CSV header\n",
        "        next(csv_reader)\n",
        "\n",
        "        for row in csv_reader:\n",
        "            label = row[2]       # Third column\n",
        "            id = int(row[3])     # Fourth column\n",
        "\n",
        "            # Add the pair to the dictionary if it doesn't already exist\n",
        "            if id not in classes:\n",
        "                classes[id] = label\n",
        "\n",
        "    return classes\n",
        "\n",
        "def show_grid(dataset: GroceryStoreDataset, classes: dict) -> None:\n",
        "    \"\"\"Shows a grid with random images taken from the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: the dataset containing the images.\n",
        "        process: a function to apply on the images before showing them.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    indices_random = np.random.randint(10, size=10, high=len(classes.keys()))\n",
        "\n",
        "    for count, idx in enumerate(indices_random):\n",
        "        fig.add_subplot(2, 5, count + 1)\n",
        "        item = dataset.__getitem__(idx) # (Tensor, idx)\n",
        "        title = classes[item[1]]\n",
        "        plt.title(title)\n",
        "        image_processed = item[0]\n",
        "        plt.imshow(T.ToPILImage()(image_processed))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "def parse_compose(v):\n",
        "  res = []\n",
        "  for t in str(v).split(\"\\n\")[1:]:\n",
        "    res.append(t.strip(\"    \"))\n",
        "  return res[:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F1cwsSnH8qO"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5mITuuvH8qP",
        "outputId": "3fcb14f3-a1b2-4285-d21e-3651ce09d7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please set GPU via Edit -> Notebook Settings\n"
          ]
        }
      ],
      "source": [
        "fix_random(seed=42)\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  print(\"All good, a GPU is available\")\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  print(\"Please set GPU via Edit -> Notebook Settings\")\n",
        "\n",
        "old_cfg = {\n",
        "    \"resize_size\": 256,\n",
        "    \"crop_size\": 224,\n",
        "\n",
        "    \"batch_size\": 4,\n",
        "    \"num_epochs\": 20,\n",
        "\n",
        "    \"lr\": 1e-3,\n",
        "    \"wd\": 1e-4,\n",
        "    \"step_size\": 5\n",
        "}\n",
        "\n",
        "cfg = {\n",
        "    \"resize_size\": 256,\n",
        "    \"crop_size\": 224,\n",
        "    \"batch_size\": 512,  \n",
        "    \"num_epochs\": 20,\n",
        "    \"lr\": 1e-3,  \n",
        "    \"wd\": 1e-4,  \n",
        "    \"step_size\": 5  \n",
        "}\n",
        "\n",
        "# CHOOSE WHICH MODEL TO TRAIN\n",
        "FLAG = \"ResNet-18\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1e0PtlZH8qQ"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nb6xOKMdH8qR"
      },
      "outputs": [],
      "source": [
        "# In  order to convert integer classes into their literal\n",
        "classes = extract_classes(csv_file_path = 'GroceryStoreDataset/dataset/classes.csv')\n",
        "\n",
        "# Preprocessing\n",
        "mean_image_net = [0.485, 0.456, 0.406]                              # FIXME\n",
        "std_image_net = [0.229, 0.224, 0.225]                               # FIXME\n",
        "data_transforms = {\n",
        "    # \"train\": T.Compose([\n",
        "    #                     T.RandomResizedCrop(cfg[\"crop_size\"]),      # FIXME\n",
        "    #                     T.RandomHorizontalFlip(),                   # FIXME\n",
        "    #                     T.ToTensor(),                               # FIXME\n",
        "    #                     T.Normalize(mean_image_net, std_image_net)  # FIXME\n",
        "    #                 ]),\n",
        "    \"train\": T.Compose([\n",
        "        T.RandomResizedCrop(cfg[\"crop_size\"]),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        T.RandomRotation(degrees=15),\n",
        "        T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "        T.RandomApply([T.GaussianBlur(kernel_size=3)], p=0.5),\n",
        "        # T.RandomErasing(p=0.5),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean_image_net, std_image_net)\n",
        "    ]),\n",
        "\n",
        "    \"val\": T.Compose([\n",
        "                        T.Resize(cfg[\"resize_size\"]),               # FIXME\n",
        "                        T.CenterCrop(cfg[\"crop_size\"]),             # FIXME\n",
        "                        T.ToTensor(),                               # FIXME\n",
        "                        T.Normalize(mean_image_net, std_image_net)  # FIXME\n",
        "                    ]),\n",
        "\n",
        "    \"test\": T.Compose([\n",
        "                        T.ToTensor(),                               # FIXME\n",
        "                        T.Resize(cfg[\"resize_size\"]),               # FIXME\n",
        "                    ]) # DEBUG\n",
        "}\n",
        "\n",
        "# Datasets\n",
        "data_train = GroceryStoreDataset(split=\"train\", transform=data_transforms[\"train\"])\n",
        "data_val = GroceryStoreDataset(split=\"val\", transform=data_transforms[\"val\"])\n",
        "data_test = GroceryStoreDataset(split=\"test\", transform=data_transforms[\"test\"])\n",
        "\n",
        "# DEBUG\n",
        "# show_grid(dataset=data_train, classes=classes)\n",
        "# show_grid(dataset=data_test, classes=classes)\n",
        "# show_grid(dataset=data_val, classes=classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1de1sRClH8qS"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Define the fully connected layers\n",
        "        self.fc1 = nn.Linear(8 * 112 * 112, 64)  # Assuming input size is (3, 224, 224)\n",
        "        self.fc2 = nn.Linear(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through convolutional layer with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pass through fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def layers(self):\n",
        "        for name, params in self.named_parameters():\n",
        "            print(f\"{name}: {params.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JdUc0RZLH8qT"
      },
      "outputs": [],
      "source": [
        "class MediumCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(MediumCNN, self).__init__()\n",
        "\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Define the fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # Assuming input size is (3, 224, 224)\n",
        "        self.fc2 = nn.Linear(128, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through convolutional layers with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pass through fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def layers(self):\n",
        "        for name, params in self.named_parameters():\n",
        "            print(f\"{name}: {params.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "\n",
        "        # Define the convolutional layers with batch normalization\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # Define the fully connected layers with dropout\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)  # Assuming input size is (3, 224, 224)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through convolutional layers with ReLU activation, batch normalization, and max pooling\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pass through fully connected layers with dropout\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def layers(self):\n",
        "        for name, params in self.named_parameters():\n",
        "            print(f\"{name}: {params.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation of ResNet-N\n",
        "class BasicBlock(nn.Module):\n",
        "    # BasicBlock is the fundamental building block of ResNet\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # First convolutional layer in the block\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)  # Batch normalization\n",
        "        # Second convolutional layer in the block\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)  # Batch normalization\n",
        "        self.downsample = downsample  # Downsample layer if required to match dimensions\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x  # Save the input tensor (skip connection)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            # Apply downsample to the identity if dimensions don't match\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity  # Add skip connection\n",
        "        out = F.relu(out)  # Apply ReLU activation\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        # Initial convolutional layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)  # Batch normalization\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # Max pooling\n",
        "\n",
        "        # Create the layers of residual blocks\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # Adaptive average pooling and fully connected layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        # Helper function to create a layer with multiple blocks\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            # If the dimensions do not match, create a downsample layer\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        # The first block in the layer\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        # The remaining blocks in the layer\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the initial layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Forward pass through each residual layer\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Forward pass through the final layers\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)  # Flatten the tensor\n",
        "        x = self.fc(x)  # Fully connected layer\n",
        "\n",
        "        return x\n",
        "\n",
        "def ResNet18(n_classes):\n",
        "    # Function to create a ResNet-18 model (N=18)\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoXt8nCUH8qU",
        "outputId": "5ecbeec6-1b8c-4dab-fc39-8d73832e9b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight: torch.Size([16, 3, 3, 3])\n",
            "conv1.bias: torch.Size([16])\n",
            "conv2.weight: torch.Size([32, 16, 3, 3])\n",
            "conv2.bias: torch.Size([32])\n",
            "conv3.weight: torch.Size([64, 32, 3, 3])\n",
            "conv3.bias: torch.Size([64])\n",
            "fc1.weight: torch.Size([128, 50176])\n",
            "fc1.bias: torch.Size([128])\n",
            "fc2.weight: torch.Size([43, 128])\n",
            "fc2.bias: torch.Size([43])\n"
          ]
        }
      ],
      "source": [
        "match FLAG :\n",
        "    case \"simple\": model = SimpleCNN(n_classes=len(classes))\n",
        "    case \"medium\": model = MediumCNN(n_classes=len(classes))\n",
        "    case \"complex\": model = ComplexCNN(n_classes=len(classes))\n",
        "    case \"ResNet-18\": model = ResNet18(n_classes=len(classes))\n",
        "    case _ : raise NameError(\"Unknown model in FLAG\")\n",
        "\n",
        "# Verifies if the model is already on the device\n",
        "if next(model.parameters()).device != device:\n",
        "    model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(\n",
        "    model,\n",
        "    input_size=(3, cfg[\"crop_size\"], cfg[\"crop_size\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDQSuPmyH8qW"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s26-iuCUH8qX"
      },
      "outputs": [],
      "source": [
        "# For automating batching\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    data_train,\n",
        "    batch_size=cfg[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "loader_val = DataLoader(\n",
        "    data_val,\n",
        "    batch_size=cfg[\"batch_size\"],\n",
        "    shuffle=False\n",
        ")\n",
        "loader_test = DataLoader(\n",
        "    data_test,\n",
        "    batch_size=cfg[\"batch_size\"],\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fKCGB9a9H8qY"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self,\n",
        "            model: nn.Module,\n",
        "            train_loader: DataLoader,\n",
        "            val_loader: DataLoader,\n",
        "            test_loader: DataLoader,\n",
        "            device: torch.device,\n",
        "            num_classes: int\n",
        "        ) -> None:\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.num_epochs = cfg[\"num_epochs\"]\n",
        "\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"wd\"])\n",
        "        num_steps = self.num_epochs * len(train_loader)\n",
        "        self.scheduler = OneCycleLR(self.optimizer, cfg[\"lr\"], total_steps=num_steps)\n",
        "\n",
        "        self.step = 0\n",
        "        self.best_acc = 0.0\n",
        "\n",
        "        wandb.init(name=cfg[\"run_name\"], entity=WANDB_USER, project=WANDB_PROJECT, config=cfg)\n",
        "        self.ckpt_path = Path(\"ckpts\")\n",
        "        self.ckpt_path.mkdir(exist_ok=True)\n",
        "\n",
        "    def logfn(self, values: Dict[str, Any]) -> None:\n",
        "        wandb.log(values, step=self.step, commit=False)\n",
        "\n",
        "    def train(self) -> None:\n",
        "        self.training_time = time.time()\n",
        "        for _ in tqdm(range(self.num_epochs), desc=\"Epoch\"):\n",
        "            self.model.train()\n",
        "\n",
        "            for imgs, labels in self.train_loader:\n",
        "                imgs = imgs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                pred = self.model(imgs)\n",
        "                # print(pred.shape, labels.shape)\n",
        "                loss = F.cross_entropy(pred, labels)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                if self.step % 10 == 0:\n",
        "                    self.logfn({\"train/loss\": loss.item()})\n",
        "                    self.logfn({\"train/lr\": self.scheduler.get_last_lr()[0]})\n",
        "\n",
        "                self.step += 1\n",
        "\n",
        "            self.eval(\"train\")\n",
        "            self.eval(\"val\")\n",
        "\n",
        "        wandb.finish()\n",
        "        self.training_time = time.time() - self.training_time\n",
        "        \n",
        "        \n",
        "    # def test(self) -> None:\n",
        "    #     wandb.init(name=cfg[\"run_name\"]+\"_test\", entity=WANDB_USER, project=WANDB_PROJECT, config=cfg)\n",
        "    #     self.eval(\"test\")\n",
        "    #     wandb.finish()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval(self, split: str) -> None:\n",
        "        self.model.eval()\n",
        "\n",
        "        if split == \"train\":\n",
        "            loader = self.train_loader\n",
        "        elif split == \"val\":\n",
        "            loader = self.val_loader\n",
        "        # elif split == \"test\":\n",
        "        #     loader = self.test_loader \n",
        "        else:\n",
        "            raise ValueError(f\"Unknown split: {split}\")\n",
        "        \n",
        "        acc = Accuracy(\"multiclass\", num_classes=self.num_classes).to(self.device)\n",
        "\n",
        "        losses = []\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            pred = self.model(imgs)\n",
        "            loss = F.cross_entropy(pred, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            pred_softmax = F.softmax(pred, dim=-1)\n",
        "            acc(pred_softmax, labels)\n",
        "\n",
        "        loss = sum(losses) / len(losses)\n",
        "        accuracy = acc.compute()\n",
        "\n",
        "        self.logfn({f\"{split}/loss\": loss})\n",
        "        self.logfn({f\"{split}/acc\": accuracy})\n",
        "\n",
        "        if accuracy > self.best_acc and split == \"val\":\n",
        "            self.best_acc = accuracy\n",
        "            torch.save(self.model.state_dict(), self.ckpt_path / f\"{wandb.run.name}.pt\")\n",
        "            self.best_model = copy.deepcopy(self.model)\n",
        "            \n",
        "    def save_model_params(self, cfg, data_transforms):\n",
        "        model_dir = os.path.join(\"params\", f\"{FLAG}_model\")\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        \n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")  # in order not to have duplicates\n",
        "        training_time_formatted = time.strftime('%H-%M-%S', time.gmtime(self.training_time))\n",
        "        file_name = f\"ACC={self.best_acc:.2f}____TT={training_time_formatted}____TM={timestamp}.json\"\n",
        "        file_path = os.path.join(model_dir, file_name)\n",
        "        \n",
        "        combined_params = {\n",
        "            \"cfg\": cfg,\n",
        "            \"data_transforms\": {k: parse_compose(v) for k,v in data_transforms.items()},\n",
        "            \"model_structure\" : parse_compose(model)\n",
        "        }\n",
        "        \n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(combined_params, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "5a10f82ca864429e8d6ab515c8278838",
            "436633b8305b4cadb88d33a4cc49002f",
            "deb93a211b334c5e8fd49599044a5bf8",
            "8061d8d453c948d3836d0623b5662f94",
            "ea2b67c242c742cd99e1a479d34413ed",
            "25079fe11b9343fb8727339219d469ed",
            "b8eb1e4fd3cd49718aa1eab9faea38c1",
            "1199eac79f464777a1d1ee06ab3986c2",
            "03bf83433b6f449baa76e931ab758c3e",
            "15d80947a63140f789bcf396a2667c65",
            "a6a78df097364ca4b5ec82048f414d15",
            "092e6d9e985d4846b53c8cddddde2852",
            "582a536b772b4d0aaf5af66a9009ea5f",
            "4045b24a76ee490c89a6a04f8d63ac68",
            "d0a048b9dafd4d9983f42ce218180bc9",
            "8bd4034799874279af8cd121460530ae",
            "41fcf1cbe05c4b40a12ba26d64fdd524",
            "0f03c651bdc044809283cc8130de8365",
            "0d22fe2de90a450fa5c9e57d43464ce7"
          ]
        },
        "id": "seJ2M-SvJYDu",
        "outputId": "547e1be9-54da-4f65-d1e4-bb597fa3d252"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240724_151714-eeodwidn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2/runs/eeodwidn' target=\"_blank\">prova</a></strong> to <a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2' target=\"_blank\">https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2/runs/eeodwidn' target=\"_blank\">https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2/runs/eeodwidn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a10f82ca864429e8d6ab515c8278838",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "092e6d9e985d4846b53c8cddddde2852",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>▁▂▃▃▃▃▅▅▅▆▆▆▇▇▇█████</td></tr><tr><td>train/loss</td><td>█▅▇▅▃▃▄▃▅▃▄▃▃▂▄▄▄▂▂▁▃▂▄▂▂▁▁▂▄▂▃▂▁▁▁▂▁▁▂▁</td></tr><tr><td>train/lr</td><td>▁▂▂▃▃▄▅▆▆▇███████▇▇▇▇▆▆▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val/acc</td><td>▁▂▂▂▄▄▅▅▅▅▆▇▇▇▇█████</td></tr><tr><td>val/loss</td><td>█▆▅▅▄▃▂▄▄▃▃▂▁▁▃▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/acc</td><td>0.85985</td></tr><tr><td>train/loss</td><td>0.46328</td></tr><tr><td>train/lr</td><td>0.0</td></tr><tr><td>val/acc</td><td>0.54054</td></tr><tr><td>val/loss</td><td>1.93772</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">prova</strong> at: <a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2/runs/eeodwidn' target=\"_blank\">https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2/runs/eeodwidn</a><br/> View project at: <a href='https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2' target=\"_blank\">https://wandb.ai/lollopelle-2-universit-di-bologna/IPCV-assignment-2</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240724_151714-eeodwidn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cfg[\"run_name\"] = \"run: \"+FLAG\n",
        "\n",
        "# Wandb key: 3f0834114b4b33656e70323616fa377c30c83542\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    loader_train,\n",
        "    loader_val,\n",
        "    loader_test,\n",
        "    device,\n",
        "    num_classes=len(classes.keys())\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX9qBRU4oTrS",
        "outputId": "9c43a9eb-2a63-4591-e63f-29ec2fade941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best val acc = 0.541\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best val acc = {trainer.best_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log results\n",
        "trainer.save_model_params(cfg, data_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkWEqSPoUIL3"
      },
      "source": [
        "## Part 2: fine-tune an existing network\n",
        "\n",
        "Your goal is to fine-tune a pretrained **ResNet-18** model on `GroceryStoreDataset`. Use the implementation provided by PyTorch, do not implement it yourselves! (i.e. exactly what you **could not** do in the first part of the assignment). Specifically, you must use the PyTorch ResNet-18 model pretrained on ImageNet-1K (V1). Divide your fine-tuning into two parts:\n",
        "\n",
        "1. First, fine-tune the Resnet-18 with the same training hyperparameters you used for your best model in the first part of the assignment.\n",
        "1. Then, tweak the training hyperparameters in order to increase the accuracy on the validation split of `GroceryStoreDataset`. Justify your choices by analyzing the training plots and/or citing sources that guided you in your decisions (papers, blog posts, YouTube videos, or whatever else you find enlightening). You should consider yourselves satisfied once you obtain a classification accuracy on the **validation** split **between 80 and 90%**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03bf83433b6f449baa76e931ab758c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "092e6d9e985d4846b53c8cddddde2852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_582a536b772b4d0aaf5af66a9009ea5f",
              "IPY_MODEL_4045b24a76ee490c89a6a04f8d63ac68"
            ],
            "layout": "IPY_MODEL_d0a048b9dafd4d9983f42ce218180bc9"
          }
        },
        "0d22fe2de90a450fa5c9e57d43464ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f03c651bdc044809283cc8130de8365": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1199eac79f464777a1d1ee06ab3986c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d80947a63140f789bcf396a2667c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25079fe11b9343fb8727339219d469ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4045b24a76ee490c89a6a04f8d63ac68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f03c651bdc044809283cc8130de8365",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d22fe2de90a450fa5c9e57d43464ce7",
            "value": 1
          }
        },
        "41fcf1cbe05c4b40a12ba26d64fdd524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "436633b8305b4cadb88d33a4cc49002f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25079fe11b9343fb8727339219d469ed",
            "placeholder": "​",
            "style": "IPY_MODEL_b8eb1e4fd3cd49718aa1eab9faea38c1",
            "value": "Epoch: 100%"
          }
        },
        "582a536b772b4d0aaf5af66a9009ea5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd4034799874279af8cd121460530ae",
            "placeholder": "​",
            "style": "IPY_MODEL_41fcf1cbe05c4b40a12ba26d64fdd524",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "5a10f82ca864429e8d6ab515c8278838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_436633b8305b4cadb88d33a4cc49002f",
              "IPY_MODEL_deb93a211b334c5e8fd49599044a5bf8",
              "IPY_MODEL_8061d8d453c948d3836d0623b5662f94"
            ],
            "layout": "IPY_MODEL_ea2b67c242c742cd99e1a479d34413ed"
          }
        },
        "8061d8d453c948d3836d0623b5662f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d80947a63140f789bcf396a2667c65",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a78df097364ca4b5ec82048f414d15",
            "value": " 20/20 [1:30:53&lt;00:00, 272.85s/it]"
          }
        },
        "8bd4034799874279af8cd121460530ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a78df097364ca4b5ec82048f414d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8eb1e4fd3cd49718aa1eab9faea38c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0a048b9dafd4d9983f42ce218180bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb93a211b334c5e8fd49599044a5bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1199eac79f464777a1d1ee06ab3986c2",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bf83433b6f449baa76e931ab758c3e",
            "value": 20
          }
        },
        "ea2b67c242c742cd99e1a479d34413ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
